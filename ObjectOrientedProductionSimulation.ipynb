{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from dateutil import rrule, parser\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import date, datetime, timedelta\n",
    "from intervaltree import Interval, IntervalTree\n",
    "#from generate_operators_availability import generate_operator_availability\n",
    "\n",
    "# Definition of the different classes\n",
    "@dataclass\n",
    "class Operator:\n",
    "    name: str\n",
    "    skills: list\n",
    "    holidays: IntervalTree\n",
    "    availabilty: IntervalTree = field(default_factory=IntervalTree)\n",
    "    shift: list = field(default_factory=list)\n",
    "\n",
    "@dataclass\n",
    "class Step:\n",
    "    name: str\n",
    "    step_number: int\n",
    "    duration: timedelta\n",
    "    capacity: int\n",
    "    log: pd.DataFrame\n",
    "    \n",
    "# Load data from the JSON configuration file\n",
    "with open(\"SimulatorInputs.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the simulation parameters\n",
    "json_simulation_start: str = data['SimulationParameters']['simulation_start']\n",
    "simulation_start: datetime = datetime.fromisoformat(json_simulation_start)\n",
    "\n",
    "json_simeulation_end: str = data['SimulationParameters']['simulation_end']\n",
    "simulation_end: datetime = datetime.fromisoformat(json_simeulation_end)\n",
    "\n",
    "modules_planned_deliveries: str = data[\"ComponentArrivalTimes\"][\"bare modules\"]\n",
    "\n",
    "total_modules_number: int = 0\n",
    "for delivery in modules_planned_deliveries:\n",
    "    total_modules_number += modules_planned_deliveries[delivery]\n",
    "\n",
    "# Initialize instances of the operator class\n",
    "# All the operators are stored in the operators list\n",
    "operators = []\n",
    "\n",
    "# Initialize the CERN holidays to the good format\n",
    "CERN_holidays_series = pd.Series(data[\"CERNHolidays\"])\n",
    "CERN_holidays_series[:] = CERN_holidays_series.apply(lambda x: [datetime.fromisoformat(date) for date in x])\n",
    "\n",
    "for id, operator in enumerate(data[\"Operators\"]):\n",
    "    # Loads the operator's individual holidays\n",
    "    individual_holidays = pd.Series(data[\"OperatorHolidays\"][f\"Operator{id + 1}\"])\n",
    "    individual_holidays[:] = individual_holidays.apply(lambda x: [datetime.fromisoformat(date) for date in x])\n",
    "\n",
    "    # Merges the individual holidays with the CERN holidays\n",
    "    operator_holidays = pd.concat([individual_holidays, CERN_holidays_series])\n",
    "    operator_holidays[:] = operator_holidays.apply(lambda x: Interval(x[0], x[1], \"holiday\"))\n",
    "\n",
    "    # Converts the pandas series to a list and then to an interval tree\n",
    "    operator_holidays_list = operator_holidays.tolist()\n",
    "    operator_holidays_tree = IntervalTree(operator_holidays_list)\n",
    "\n",
    "    globals()[f\"Operator{id + 1}\"] = Operator(name=f\"Operator{id + 1}\", skills=operator, holidays=operator_holidays_tree)\n",
    "    operators.append(globals()[f\"Operator{id + 1}\"])\n",
    "\n",
    "\n",
    "# Initialization of the Step class instances, they are stored in the \"Chronologically_Ordered_Steps\" dict, the member log is a dataframe that will contain \n",
    "# the entry and exit dates of the modules at each step\n",
    "\n",
    "Chronologically_Ordered_Steps = {}\n",
    "for id, step in enumerate(data[\"StagesAndSteps\"]):\n",
    "    step_name = step[\"Step\"].replace(\"-\", \"_\").replace(\" \", \"_\")\n",
    "    globals()[step_name] = Step(name=step[\"Step\"], step_number=id, duration=step[\"Duration\"], capacity= step[\"Capacity\"],log=pd.DataFrame(columns=[\"Entry_Date\", \"Exit_Date\"]))\n",
    "    Chronologically_Ordered_Steps |= {step[\"Step\"]: globals()[step_name]}\n",
    "\n",
    "time: datetime = simulation_start\n",
    "finished_modules_count: int = 0 #Might be a duplicate\n",
    "\n",
    "# Initialization of the list of the differents tasks and steps to be done\n",
    "tasks_to_do: list = [task['Step'] for task in data[\"StagesAndSteps\"]]\n",
    "\n",
    "# Initialization of the dataframe that will contain the assignments of the operators\n",
    "operators_assignments: pd.DataFrame = pd.DataFrame(columns=[tasks_to_do], index=[simulation_start])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\AppData\\Local\\Temp\\ipykernel_29720\\3239257992.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Step.log = pd.concat([Step.log, df_Ready, df_WIP], ignore_index=True)\n",
      "C:\\Users\\Martin\\AppData\\Local\\Temp\\ipykernel_29720\\3239257992.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Step.log = pd.concat([Step.log, df_Ready, df_WIP], ignore_index=True)\n",
      "C:\\Users\\Martin\\AppData\\Local\\Temp\\ipykernel_29720\\3239257992.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  Step.log = pd.concat([Step.log, df_Ready, df_WIP], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Load the state of production csv data into each step\n",
    "state_of_production = pd.read_csv(\"inventory.csv\", sep=\";\", dtype={\"Quantity\":'Int64'}, index_col=0, parse_dates=[\"Launching Time\"])\n",
    "state_of_production.fillna({\"Quantity\": 0}, inplace=True)\n",
    "\n",
    "# This piece of code fills by default the missing values of the Ready components launching time\n",
    "# to simulation_start_time - duration of the task to simulate the fact that they are just ready to \n",
    "# be moved to the next step when the simulation is launched. \n",
    "for index, row in state_of_production.iterrows():   # I prefer to work with literal values of Index and Columns rather than the integer values for more reliability and legibility\n",
    "    if row[\"Quantity\"] > 0:     # We only care about the Steps where there are modules\n",
    "        for task in iter(Chronologically_Ordered_Steps):\n",
    "            if task in index:   # Looks for the task associated with the row TODO : suppress this loop by implementing yet another lookup table\n",
    "                if pd.isna(state_of_production.loc[index, \"Launching Time\"]):\n",
    "                    Time_ready_by_simulation_start = simulation_start - timedelta(minutes=Chronologically_Ordered_Steps[task].duration)   # In the last part we extract the duration associated with the task\n",
    "                    state_of_production.loc[index, \"Launching Time\"] = Time_ready_by_simulation_start\n",
    "\n",
    "# Now we fill all those initial data into the log attribute of each step\n",
    "for Step in Chronologically_Ordered_Steps.values():\n",
    "    row_Ready = state_of_production.loc[Step.name + \" Ready\"]\n",
    "    row_WIP = state_of_production.loc[Step.name + \" WIP\"]\n",
    "    df_Ready = pd.DataFrame([[row_Ready.loc[\"Launching Time\"],pd.NaT] for _ in range(row_Ready.loc[\"Quantity\"])],columns=[\"Entry_Date\", \"Exit_Date\"])\n",
    "    df_WIP = pd.DataFrame([[row_WIP.loc[\"Launching Time\"],pd.NaT] for _ in range(row_WIP.loc[\"Quantity\"])],columns=[\"Entry_Date\", \"Exit_Date\"])\n",
    "    Step.log = pd.concat([Step.log, df_Ready, df_WIP], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Steps = list(reversed(Chronologically_Ordered_Steps.values()))[:-1]\n",
    "Previous_Steps = list(reversed(Chronologically_Ordered_Steps.values()))[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Previous_Steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Step(name='FA - visual inspection of module', step_number=9, duration=10, capacity=1, log=Empty DataFrame\n",
       " Columns: [Entry_Date, Exit_Date]\n",
       " Index: []),\n",
       " Step(name='Rec - Metrology and Visual inspection of bare modules or flexes', step_number=3, duration=20, capacity=1, log=Empty DataFrame\n",
       " Columns: [Entry_Date, Exit_Date]\n",
       " Index: []),\n",
       " Step(name='Rec - PDB checks of bare modules and flexes', step_number=2, duration=10, capacity=20, log=Empty DataFrame\n",
       " Columns: [Entry_Date, Exit_Date]\n",
       " Index: [])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_to_do = []\n",
    "for Step,Previous_Step in zip(Steps, Previous_Steps):\n",
    "    time_array = np.full_like(Previous_Step.log.loc[:,\"Entry_Date\"], time)\n",
    "    time_spent_in_task = time_array - Previous_Step.log.loc[:,\"Entry_Date\"]\n",
    "    duration_delta = timedelta(minutes=Previous_Step.duration) \n",
    "    if sum(time_spent_in_task >= duration_delta) >= Step.capacity:\n",
    "        steps_to_do.append(Step)\n",
    "\n",
    "steps_to_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_to_do"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
