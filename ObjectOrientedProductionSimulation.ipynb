{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from dateutil import rrule, parser\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import date, datetime, timedelta\n",
    "from intervaltree import Interval, IntervalTree\n",
    "\n",
    "# Definition of the different classes\n",
    "@dataclass\n",
    "class Operator:\n",
    "    name: str\n",
    "    skills: list\n",
    "    holidays: IntervalTree\n",
    "    availability: IntervalTree = field(default_factory=IntervalTree)\n",
    "    shift: list = field(default_factory=list)   # Is it used ?\n",
    "\n",
    "@dataclass\n",
    "class Step:\n",
    "    name: str\n",
    "    previous_steps: list\n",
    "    duration: timedelta\n",
    "    required: timedelta\n",
    "    capacity: int\n",
    "    log: pd.DataFrame\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Step {self.name}, duration {self.duration}, capacity {self.capacity}, log {self.log}\"\n",
    "    \n",
    "# Load data from the JSON configuration file\n",
    "with open(\"SimulatorInputs.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the simulation parameters\n",
    "json_simulation_start: str = data['SimulationParameters']['simulation_start']\n",
    "simulation_start: datetime = datetime.fromisoformat(json_simulation_start)\n",
    "\n",
    "json_simeulation_end: str = data['SimulationParameters']['simulation_end']\n",
    "simulation_end: datetime = datetime.fromisoformat(json_simeulation_end)\n",
    "\n",
    "modules_planned_deliveries: str = data[\"ComponentArrivalTimes\"][\"bare modules\"]\n",
    "\n",
    "total_modules_number: int = 0\n",
    "for delivery in modules_planned_deliveries:\n",
    "    total_modules_number += modules_planned_deliveries[delivery]\n",
    "\n",
    "# Initialize instances of the operator class\n",
    "# All the operators are stored in the operators list\n",
    "operators = []\n",
    "\n",
    "# Initialize the CERN holidays to the good format\n",
    "CERN_holidays_series = pd.Series(data[\"CERNHolidays\"])\n",
    "CERN_holidays_series[:] = CERN_holidays_series.apply(lambda x: [datetime.fromisoformat(date) for date in x])\n",
    "\n",
    "for id, operator in enumerate(data[\"Operators\"]):\n",
    "    # Loads the operator's individual holidays\n",
    "    individual_holidays = pd.Series(data[\"OperatorHolidays\"][f\"Operator{id + 1}\"])\n",
    "    individual_holidays[:] = individual_holidays.apply(lambda x: [datetime.fromisoformat(date) for date in x])\n",
    "\n",
    "    # Merges the individual holidays with the CERN holidays\n",
    "    operator_holidays = pd.concat([individual_holidays, CERN_holidays_series])\n",
    "    operator_holidays[:] = operator_holidays.apply(lambda x: Interval(x[0], x[1], \"holiday\"))\n",
    "\n",
    "    # Converts the pandas series to a list and then to an interval tree\n",
    "    operator_holidays_list = operator_holidays.tolist()\n",
    "    operator_holidays_tree = IntervalTree(operator_holidays_list)\n",
    "\n",
    "    globals()[f\"Operator{id + 1}\"] = Operator(name=f\"Operator{id + 1}\", skills=data[\"Operators\"][operator], holidays=operator_holidays_tree)\n",
    "    operators.append(globals()[f\"Operator{id + 1}\"])\n",
    "\n",
    "\n",
    "# Initialization of the Step class instances, they are stored in the \"Chronologically_Ordered_Steps\" dict, the member log is a dataframe that will contain \n",
    "# the entry and exit dates of the modules at each step\n",
    "\n",
    "Chronologically_Ordered_Steps = {}\n",
    "for step in data[\"StagesAndSteps\"]:\n",
    "    step_name = step[\"Step\"].replace(\"-\", \"_\").replace(\" \", \"_\")    # Just converting the name to python valid name without blank spaces and\n",
    "\n",
    "    if step[\"Previous\"][0] == \"None\":\n",
    "        globals()[step_name] = Step(name=step[\"Step\"], previous_steps=[None], duration=timedelta(minutes = step[\"Duration\"]),required=timedelta(minutes = step[\"Required\"]), capacity= step[\"Capacity\"],log=pd.DataFrame(columns=[\"Entry_Date\", \"Exit_Date\"]))\n",
    "\n",
    "    else:\n",
    "        previous_steps = []\n",
    "        for prev_step in step[\"Previous\"]:\n",
    "            previous_steps.append(Chronologically_Ordered_Steps[prev_step])\n",
    "            globals()[step_name] = Step(name=step[\"Step\"], previous_steps=previous_steps, duration=timedelta(minutes = step[\"Duration\"]), required=timedelta(minutes = step[\"Required\"]), capacity= step[\"Capacity\"],log=pd.DataFrame(columns=[\"Entry_Date\", \"Exit_Date\"]))\n",
    "    Chronologically_Ordered_Steps |= {step[\"Step\"]: globals()[step_name]}\n",
    "\n",
    "time: datetime = simulation_start\n",
    "finished_modules_count: int = sum(S___PDB_Shipment_of_modules_to_loading_sites.log[\"Exit_Date\"].notna())\n",
    "\n",
    "############################################################################################\n",
    "# Extract the holidays, and daily shift from the data\n",
    "dict_int_to_day = {\"0\": \"Monday\", \"1\": \"Tuesday\", \"2\": \"Wednesday\", \"3\": \"Thursday\", \"4\": \"Friday\"}\n",
    "\n",
    "def generate_operators_availability(date) -> None:\n",
    "    \n",
    "    whole_day = Interval(date, date + timedelta(days=1))    #TODO: big issue with whole_day, need to bound it to the working hours of the laboratory\n",
    "    for operator in operators:\n",
    "\n",
    "        if operator.holidays.overlaps(whole_day) or date.weekday() in {5,6}:  # Check if the day is either in the holidays or weekend\n",
    "            continue  \n",
    "\n",
    "        else:\n",
    "        \n",
    "            today_shift = data[\"OperatorWorkHours\"][operator.name][dict_int_to_day[str(date.weekday())]]\n",
    "            list_today_shift = list(today_shift.keys())\n",
    "\n",
    "            # TODO: check for even number of time constraints\n",
    "            beginning_slot = list_today_shift[::2]  # Extract the beginning and ending time of the different operator's daily slots\n",
    "            ending_slot = list_today_shift[1::2]    # Implicitly we assume that there is an even number of time constraints (namely the beginning and the ending of the time slot)\n",
    "\n",
    "            for begin, end in zip(beginning_slot, ending_slot):\n",
    "                start_time = str(date)[:10] + \" \" + today_shift[begin]\n",
    "                start_time = datetime.fromisoformat(start_time)\n",
    "                end_time = str(date)[:10] + \" \" + today_shift[end]\n",
    "                end_time = datetime.fromisoformat(end_time)\n",
    "                operator.availability.add(Interval(start_time, end_time, \"idle\"))\n",
    "############################################################################################\n",
    "\n",
    "############################################################################################\n",
    "# Load the state of production csv data into each step\n",
    "state_of_production = pd.read_csv(\"inventory.csv\", sep=\";\", dtype={\"Quantity\":'Int64'}, index_col=0, parse_dates=[\"Launching Time\"])\n",
    "state_of_production.fillna({\"Quantity\": 0}, inplace=True)\n",
    "\n",
    "# This piece of code fills by default the missing values of the Ready components launching time\n",
    "# to simulation_start_time - duration of the task to simulate the fact that they are just ready to \n",
    "# be moved to the next step when the simulation is launched. \n",
    "for index, row in state_of_production.iterrows():   # I prefer to work with literal values of Index and Columns rather than the integer values for more reliability and legibility\n",
    "    if row[\"Quantity\"] > 0:     # We only care about the Steps where there are modules\n",
    "        for task in iter(Chronologically_Ordered_Steps):\n",
    "            if task in index:   # Looks for the task associated with the row TODO : suppress this loop by implementing yet another lookup table\n",
    "                if pd.isna(state_of_production.loc[index, \"Launching Time\"]):\n",
    "                    Time_ready_by_simulation_start = simulation_start - Chronologically_Ordered_Steps[task].duration  # In the last part we extract the duration associated with the task\n",
    "                    state_of_production.loc[index, \"Launching Time\"] = Time_ready_by_simulation_start\n",
    "\n",
    "# Now we fill all those initial data into the log attribute of each step\n",
    "for Step in Chronologically_Ordered_Steps.values():\n",
    "    row_Ready = state_of_production.loc[Step.name + \" Ready\"]\n",
    "    row_WIP = state_of_production.loc[Step.name + \" WIP\"]\n",
    "    df_Ready = pd.DataFrame([[row_Ready.loc[\"Launching Time\"],pd.NaT] for _ in range(row_Ready.loc[\"Quantity\"])],columns=[\"Entry_Date\", \"Exit_Date\"])\n",
    "    df_WIP = pd.DataFrame([[row_WIP.loc[\"Launching Time\"],pd.NaT] for _ in range(row_WIP.loc[\"Quantity\"])],columns=[\"Entry_Date\", \"Exit_Date\"])\n",
    "    Step.log = pd.concat([Step.log, df_Ready, df_WIP], ignore_index=True)   # TODO : maybe numpy arrays are better suited in this context, since it's a single type of datatype, in addition to that this line raises a warning\n",
    "\n",
    "def tasks_by_priority(time: timedelta) -> list: # Returns the list of tasks that can be done at the current time\n",
    "\n",
    "    steps_to_do = []\n",
    "\n",
    "    for step in list(reversed(Chronologically_Ordered_Steps.values())): \n",
    "        # First step, check if the step is ready to process new modules\n",
    "        condition = sum(pd.isna(step.log[\"Exit_Date\"])) >= step.capacity # We check if the number of steps not exited yet is greater than the capacity\n",
    "        if condition:  # If the step is not ready to process new modules\n",
    "            continue    # we break the loop and go to the next step\n",
    "\n",
    "        if step.previous_steps[0] is None:  # If previous_steps is None. That means that this the first step                        \n",
    "            continue    # By default the first step is always ready, in fact that means that there are not enough components left\n",
    "\n",
    "        else:\n",
    "            # Second step, we compute the reception capacity of the step\n",
    "            #reception_capacity = step.capacity - sum(pd.isna(step.log[\"Exit_Date\"]))  # We compute the number of modules ready to be processed in the next step\n",
    "            \n",
    "            # Now we check if among the previous steps there are enough modules ready to be processed in the next step\n",
    "            ready_to_be_processed: bool = True\n",
    "            for previous_step in Step.previous_steps:   \n",
    "\n",
    "                previous_time_array: np.ndarray = np.full_like(previous_step.log.loc[:,\"Entry_Date\"], time) \n",
    "                time_spent_in_previous_task: pd.DataFrame = previous_time_array - previous_step.log.loc[:,\"Entry_Date\"]   # Displays the time spent in the previous task for each module\n",
    "                modules_ready: int = sum((time_spent_in_previous_task >= previous_step.duration) & (pd.isna(previous_step.log[\"Exit_Date\"])))      # If there are not enough modules ready to be processed in the previous steps\n",
    "                if modules_ready <= 0:                                                       \n",
    "                    ready_to_be_processed = False\n",
    "            \n",
    "            if ready_to_be_processed:\n",
    "                steps_to_do.append(step)\n",
    "\n",
    "\n",
    "    return steps_to_do\n",
    "############################################################################################\n",
    "\n",
    "############################################################################################\n",
    "# Once a task is assigned to operators, a module has to be withdrawn \n",
    "# from the previous step and added to the next step\n",
    "def update_log(task, time):\n",
    "\n",
    "    # First step, we remove the module from the previous step\n",
    "    if task.previous_steps[0] is None:  # There is no need to update the log for the first step\n",
    "        pass\n",
    "    else:\n",
    "        for previous_step in task.previous_steps:\n",
    "            condition = (previous_step.log[\"Entry_Date\"] + previous_step.duration <= time) & (pd.isna(previous_step.log[\"Exit_Date\"]))    # Filter all the modules ready that have not been moved yet\n",
    "                # Check if any rows match the condition\n",
    "            if condition.any():\n",
    "                # Get the first index that matches the condition\n",
    "                first_matching_index = previous_step.log[condition].index[0]    # Take the first ready module and fill its exit date\n",
    "                \n",
    "                # Update the 'Exit_Date' for the first matching row\n",
    "                previous_step.log.at[first_matching_index, \"Exit_Date\"] = time\n",
    "            else:\n",
    "                print(\"There is a big issue !!\")\n",
    "\n",
    "    # Second step, we add the module to the next step\n",
    "    df = pd.DataFrame([[time, pd.NaT]], columns=[\"Entry_Date\", \"Exit_Date\"])\n",
    "    task.log = pd.concat([task.log, df], ignore_index=True)\n",
    "############################################################################################\n",
    "\n",
    "\n",
    "# Initialization of the list of the differents tasks and steps to be done\n",
    "tasks_to_do: list = [task['Step'] for task in data[\"StagesAndSteps\"]]\n",
    "\n",
    "# Initialization of the dataframe that will contain the assignments of the operators\n",
    "operators_assignments: pd.DataFrame = pd.DataFrame(columns=tasks_to_do, dtype=object)\n",
    "\n",
    "\n",
    "while (time < simulation_end or finished_modules_count < total_modules_number):\n",
    "    generate_operators_availability(time)    # TODO: Duplication of computation, we could do it once for the day\n",
    "    to_do: list = tasks_by_priority(time)\n",
    "    was_a_task_assigned: bool = False\n",
    "    for task in to_do:\n",
    "        # if two operators are available, and qualified for the task we assign them to the task\n",
    "        task_duration: Interval = Interval(time, time + task.required, task.name)\n",
    "        operators_available: list = [operator for operator in operators if operator.availability.overlaps(task_duration) and task.name in operator.skills]\n",
    "\n",
    "        # For now we chose at random two of the available operators to perform the task, the law according to which we chose the operators my be reweighted according to their skills\n",
    "        # Wire Bonding journée entière et 2 fois par semaine. \n",
    "        if len(operators_available) >= 2:\n",
    "            chosen_operators: list = np.random.choice(operators_available, 2, replace=False)\n",
    "            first_operator, second_operator = chosen_operators\n",
    "            first_operator.availability.chop(time, time + task.required)\n",
    "            second_operator.availability.chop(time, time + task.required)\n",
    "            assigned_operators = (first_operator.name, second_operator.name)\n",
    "            operators_assignments.loc[time, task.name] = assigned_operators\n",
    "            print(f\"A task was assigned at {time} to {assigned_operators} for the task {task.name}\")\n",
    "            update_log(task, time)\n",
    "            print(f\"task log : \\n{task.log}\\n\\n\")\n",
    "            for previous_steps in task.previous_steps:\n",
    "                print(f\"previous step log : \\n{previous_steps.log}\\n\\n\")\n",
    "            time += task.duration\n",
    "            was_a_task_assigned = True\n",
    "            break\n",
    "    \n",
    "    if was_a_task_assigned == False:\n",
    "        time += timedelta(minutes=60)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = datetime(2024,11,1,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry_Date</th>\n",
       "      <th>Exit_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Entry_Date, Exit_Date]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WB___Wire_bonding.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry_Date</th>\n",
       "      <th>Exit_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Entry_Date, Exit_Date]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WB___PDB_Upload_of_wire_bonding_pull_test_results.previous_steps[0].log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 11, 1, 16, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Entry_Date, dtype: object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_time_array = np.full_like(WB___PDB_Upload_of_wire_bonding_pull_test_results.previous_steps[0].log.loc[:,\"Entry_Date\"], time) \n",
    "time_spent_in_previous_task = previous_time_array - WB___PDB_Upload_of_wire_bonding_pull_test_results.previous_steps[0].log.loc[:,\"Entry_Date\"]\n",
    "time_spent_in_previous_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: bool)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = (time_spent_in_previous_task >= WB___PDB_Upload_of_wire_bonding_pull_test_results.previous_steps[0].duration) & (pd.isna(WB___PDB_Upload_of_wire_bonding_pull_test_results.previous_steps[0].log[\"Exit_Date\"]))\n",
    "condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_to_do = []\n",
    "\n",
    "for Step in list(reversed(Chronologically_Ordered_Steps.values())): # This is not the good way to do it, we need to start from the last step and branch out to the first steps\n",
    "\n",
    "    if Step.previous_steps[0] is None:  # If previous_steps is None. That means that this the first step \n",
    "                                \n",
    "        steps_to_do.append(Step)    # By default the first step is always ready, in fact that means that there are not enough components left\n",
    "\n",
    "    else:\n",
    "        for previous_step in Step.previous_steps:   \n",
    "            previous_time_array = np.full_like(previous_step.log.loc[:,\"Entry_Date\"], time) \n",
    "            time_spent_in_previous_task = previous_time_array - previous_step.log.loc[:,\"Entry_Date\"]   # Displays the time spent in the previous task for each module\n",
    "            if sum(time_spent_in_previous_task >= previous_step.duration) < Step.capacity:              # If there are not enough modules ready to be processed in the next step                                                        \n",
    "                continue                                                                                # we break the loop and go to the next step\n",
    "            else : \n",
    "                steps_to_do.append(Step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'log'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tasks_by_priority(time)\n",
      "Cell \u001b[1;32mIn[1], line 166\u001b[0m, in \u001b[0;36mtasks_by_priority\u001b[1;34m(time)\u001b[0m\n\u001b[0;32m    163\u001b[0m ready_to_be_processed: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m previous_step \u001b[38;5;129;01min\u001b[39;00m Step\u001b[38;5;241m.\u001b[39mprevious_steps:   \n\u001b[1;32m--> 166\u001b[0m     previous_time_array: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull_like(previous_step\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntry_Date\u001b[39m\u001b[38;5;124m\"\u001b[39m], time) \n\u001b[0;32m    167\u001b[0m     time_spent_in_previous_task: pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m=\u001b[39m previous_time_array \u001b[38;5;241m-\u001b[39m previous_step\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntry_Date\u001b[39m\u001b[38;5;124m\"\u001b[39m]   \u001b[38;5;66;03m# Displays the time spent in the previous task for each module\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     modules_ready: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m((time_spent_in_previous_task \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m previous_step\u001b[38;5;241m.\u001b[39mduration) \u001b[38;5;241m&\u001b[39m (pd\u001b[38;5;241m.\u001b[39misna(previous_step\u001b[38;5;241m.\u001b[39mlog[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExit_Date\u001b[39m\u001b[38;5;124m\"\u001b[39m])))      \u001b[38;5;66;03m# If there are not enough modules ready to be processed in the previous steps\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'log'"
     ]
    }
   ],
   "source": [
    "tasks_by_priority(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WB___PDB_Upload_of_wire_bonding_pull_test_results.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
